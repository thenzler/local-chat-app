# Local Chat App

Eine vollstÃ¤ndig lokale Chat-Anwendung mit LLM und Vektorsuche, ohne Cloud-AbhÃ¤ngigkeiten oder API-Kosten.

## ğŸ¯ Beschreibung

Diese Anwendung ist eine leistungsstarke, kostengÃ¼nstige Alternative zu Cloud-basierten Chatbot-LÃ¶sungen wie Azure OpenAI. Sie bietet eine moderne, benutzerfreundliche OberflÃ¤che fÃ¼r die Interaktion mit Ihren eigenen Dokumenten durch lokale Sprachmodelle (LLMs) und ermÃ¶glicht semantische Suche ohne AbhÃ¤ngigkeit von externen Diensten oder API-Kosten.

## ğŸ“‹ Features

- **Lokale Sprachmodelle**: Integration mit Ollama fÃ¼r vollstÃ¤ndig lokale LLM-AusfÃ¼hrung
- **Intelligente Modellverwaltung**: Automatische Hardwareerkennung und Modellempfehlungen
- **Semantische Vektorsuche**: Leistungsstarke Qdrant-Integration mit Vektoreinbettungen
- **Dokumentenreferenzierung**: Indizierung von PDF-, Word- und Textdateien mit Quellenangaben
- **Moderne Chat-UI**: Responsive BenutzeroberflÃ¤che mit Echtzeit-Interaktionen
- **Automatische Quellenangaben**: Alle aus Dokumenten stammenden Informationen werden mit Quellen zitiert
- **Fallback zu allgemeinem Wissen**: Kennzeichnung von Antworten aus dem Modellwissen vs. Dokumentenwissen
- **Token-Limitierung**: Intelligente Verwaltung von KontextgrÃ¶ÃŸe fÃ¼r optimale Leistung

## ğŸ¤” Warum Local Chat App statt Azure OpenAI?

### ğŸ’° Kosteneinsparung
- **Keine API-Kosten**: Azure OpenAI berechnet pro Token (Eingabe und Ausgabe)
- **Keine Ãœberraschungen**: Keine unerwarteten Rechnungen durch intensive Nutzung

### ğŸ›¡ï¸ Datenschutz und Kontrolle
- **Daten bleiben lokal**: Alle Dokumente und Anfragen bleiben in Ihrer Kontrolle
- **Keine Datenbereitstellung**: Ihre Unternehmensdaten werden nicht fÃ¼r AI-Training verwendet

### ğŸš€ Leistung und Anpassbarkeit
- **Modellauswahl**: FlexibilitÃ¤t beim Wechsel zwischen verschiedenen Modellen
- **Angepasste Systemanforderungen**: Auswahl von Modellen basierend auf Ihrer Hardware
- **VollstÃ¤ndige Anpassungskontrolle**: Ã„ndern Sie den Code nach Ihren BedÃ¼rfnissen

### ğŸ”Œ OfflinefÃ¤higkeit
- **Keine InternetabhÃ¤ngigkeit**: Funktioniert vollstÃ¤ndig ohne Internetverbindung
- **Keine Ausfallzeiten**: Nicht betroffen von Cloud-Dienst-Unterbrechungen

## ğŸ› ï¸ Technologie-Stack

### Frontend
- HTML5, CSS3 mit Custom Properties und responsivem Design
- Vanilla JavaScript ohne externe Frameworks

### Backend
- Node.js mit Express
- Ollama fÃ¼r lokale LLM-Integration
- Qdrant fÃ¼r Vektordatenbank
- Transformers.js fÃ¼r Einbettungen

## ğŸš€ Erste Schritte

Eine detaillierte Installations- und Benutzungsanleitung finden Sie in der [INSTALLATION.md](INSTALLATION.md).

## ğŸ§™â€â™‚ï¸ Verbesserte Funktionen

Im Vergleich zur ursprÃ¼nglichen Azure-basierten Version bietet diese Anwendung:

1. **Modellverwaltung**: Einfache Installation, Aktivierung und Verwaltung von LLMs
2. **Hardware-bewusste Empfehlungen**: Automatische Anpassung an Ihr System
3. **Verbesserte semantische Suche**: Hochwertige Vektorsuche mit optimierten Einbettungen
4. **Effizientes Chunking**: Intelligentes Aufteilen von Dokumenten an Satzgrenzen
5. **GrÃ¶ÃŸere DokumentunterstÃ¼tzung**: Verbesserte Token-Verwaltung ermÃ¶glicht grÃ¶ÃŸere Dokumente

## ğŸ“Š Leistungsvergleich

| Funktion | Local Chat App | Azure OpenAI |
|---|---|---|
| Kosten | Einmalige Server-/Hardware-Kosten | Fortlaufende API-Kosten pro Token |
| Latenz | AbhÃ¤ngig von lokaler Hardware | AbhÃ¤ngig von Internetverbindung |
| Datenschutz | 100% lokal | Daten werden an Azure gesendet |
| Anpassbarkeit | VollstÃ¤ndiger Code-Zugriff | Begrenzt auf API-Parameter |
| Modellanpassung | Freie Modellauswahl | Begrenzt auf verfÃ¼gbare Azure-Modelle |
| Offlinebetrieb | VollstÃ¤ndig offlinefÃ¤hig | Erfordert Internetverbindung |

## ğŸ”§ Konfiguration

Die Anwendung ist hochgradig konfigurierbar durch Umgebungsvariablen. Detaillierte Informationen finden Sie in der `.env.example`-Datei.

## ğŸš§ In Entwicklung

- [ ] Chat-Verlaufs-Management mit lokaler Datenbank
- [ ] Mehrbenutzer-UnterstÃ¼tzung und Authentifizierung
- [ ] Web-basierte Dokumenten-Upload-Schnittstelle
- [ ] Erweiterte Analyseoptionen fÃ¼r indizierte Dokumente

## ğŸ“š Referenzen

- [Ollama](https://ollama.com/) - Framework fÃ¼r lokale LLMs
- [Qdrant](https://qdrant.tech/) - Vektordatenbank fÃ¼r Ã„hnlichkeitssuche
- [Transformers.js](https://huggingface.co/docs/transformers.js) - ML-Modelle fÃ¼r den Browser und Node.js

## ğŸ“„ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe die [LICENSE](LICENSE) Datei fÃ¼r Details.